{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pinecone 101 Webinar\n",
    "In this notebook, we will learn how to create and index, embed data into vectors, load the vectors, and execute queries."
   ],
   "id": "2a4e764c0b639c29"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Libraries"
   ],
   "id": "556eff6203b1aabe"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-pinecone 0.1.1 requires pinecone-client<4.0.0,>=3.2.2, but you have pinecone-client 3.2.1 which is incompatible.\n",
      "pinecone-datasets 0.7.0 requires pyarrow<12.0.0,>=11.0.0, but you have pyarrow 14.0.1 which is incompatible.\n",
      "pinecone-datasets 0.7.0 requires pydantic<2.0.0,>=1.10.5, but you have pydantic 2.0 which is incompatible.\u001B[0m\u001B[31m\n",
      "\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.0\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.1.1\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU pinecone-client==3.2.1 pinecone-notebooks tqdm\n",
    "\n"
   ],
   "id": "5cdf512f7f2e30a9"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Authenticate' from 'pinecone_notebooks.colab' (/Users/rick/Library/Python/3.9/lib/python/site-packages/pinecone_notebooks/colab/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpinecone_notebooks\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcolab\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Authenticate\n\u001B[1;32m      2\u001B[0m Authenticate()\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n",
      "\u001B[0;31mImportError\u001B[0m: cannot import name 'Authenticate' from 'pinecone_notebooks.colab' (/Users/rick/Library/Python/3.9/lib/python/site-packages/pinecone_notebooks/colab/__init__.py)"
     ]
    }
   ],
   "source": [
    "from pinecone_notebooks.colab import Authenticate\n",
    "Authenticate()\n",
    "\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from google.colab import files\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch"
   ],
   "id": "cd97362e7f072e7c"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Pinecone Connection"
   ],
   "id": "95e0fe4e1221078f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize connection to Pinecone (get API key at app.pinecone.io)\n",
    "api_key = os.getenv('PINECONE_API_KEY')\n",
    "\n",
    "# Configure Pinecone client\n",
    "pc = Pinecone(api_key=api_key, source_tag='pinecone-notebooks:pinecone-101')\n",
    "\n",
    "# Get cloud and region settings\n",
    "cloud = os.getenv('PINECONE_CLOUD', 'aws')\n",
    "region = os.getenv('PINECONE_REGION', 'us-east-1')\n",
    "\n",
    "# Define serverless specifications\n",
    "spec = ServerlessSpec(cloud=cloud, region=region)\n",
    "\n",
    "# Define index name\n",
    "index_name = 'pinecone101'"
   ],
   "id": "e5adf940500c5209"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Create Index",
   "id": "e0ef91d4dfc6f82f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index pinecone101 already exists.\n"
     ]
    }
   ],
   "source": [
    "# Check existing indexes\n",
    "existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
    "\n",
    "if index_name not in existing_indexes:\n",
    "    # Create index if it does not exist\n",
    "    pc.create_index(index_name, dimension=384, metric='cosine', spec=spec)\n",
    "    # Wait for index to be initialized\n",
    "    while not pc.describe_index(index_name).status['ready']:\n",
    "        time.sleep(1)\n",
    "    print(f\"Index {index_name} has been successfully created.\")\n",
    "else:\n",
    "    print(f\"Index {index_name} already exists.\")"
   ],
   "id": "d39520699392163e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data\n",
    "The data is based on simulated doctor's notes for numerous patients."
   ],
   "id": "fd43e8e03c1d45b1"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload and Read Data"
   ],
   "id": "bdda781680e2d124"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Upload the file from your local machine to Google Colab\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Step 2: Assuming the file is uploaded, read it into a DataFrame\n",
    "file_name = next(iter(uploaded.keys()))\n",
    "df = pd.read_json(file_name, orient='records', lines=True)\n",
    "\n",
    "# Show head of the DataFrame\n",
    "df.head()"
   ],
   "id": "4a1b3bc1cfba4f99"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Index and Upload Data"
   ],
   "id": "eb651746fdab451c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to index\n",
    "index = pc.Index(index_name)\n",
    "time.sleep(1)\n",
    "\n",
    "# View index stats\n",
    "index.describe_index_stats()\n",
    "\n",
    "# Upsert data into index from DataFrame\n",
    "index.upsert_from_dataframe(df)"
   ],
   "id": "385bb027f485a52e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding and Querying"
   ],
   "id": "976d5cce9bc8efe6"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Embedding Function"
   ],
   "id": "c543a5a38b1e99e7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(input_question):\n",
    "    model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "    encoded_input = tokenizer(input_question, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "\n",
    "    embedding = model_output.last_hidden_state[0].mean(dim=0)\n",
    "    return embedding"
   ],
   "id": "506e4bb0798ceb48"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and Execute Query"
   ],
   "id": "ee57ce2b49f5914e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original question: what if my patient has knee pain\n",
      "---\n",
      "Results:\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "# Build a query to search\n",
    "question = \"what if my patient has knee pain\"\n",
    "query = get_embedding(question).tolist()\n",
    "\n",
    "# Get results\n",
    "results = index.query(vector=[query], top_k=3, include_metadata=True)\n",
    "\n",
    "# Sort results by score in descending order\n",
    "sorted_matches = sorted(results['matches'], key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "# Print results\n",
    "print(f'Original question: {question}')\n",
    "print('---\\nResults:\\n--------------')\n",
    "for match in sorted_matches:\n",
    "    print(f'ID: {match[\"id\"]}')\n",
    "    print(f'Score: {match[\"score\"]}')\n",
    "    print(f'Metadata: {match[\"metadata\"]}')\n",
    "    print('---')"
   ],
   "id": "b6487ae2ff6aeef5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
